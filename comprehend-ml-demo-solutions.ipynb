{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS Hands on Labs - Machine Learning - AWS Comprehend (2020/04/05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notes if you are setting the notebook up in your personal environment:\n",
    "\n",
    "1. Ensure ComprehendFullAccess Policy has been attached to the IAM Role that SageMaker uses\n",
    "2. Ensure SageMaker has access to the S3 Bucket defined in `DATA_BUCKET` below, and has an appropriate S3 Policy (e.g. AmazonS3FullAccess) attached to the IAM Role that SageMaker uses\n",
    "\n",
    "##### For the Topic Modelling section:\n",
    "1. Ensure the role defined in `DATA_ACCESS_ROLE_ARN` below has access to the `DATA_BUCKET`. Remember that this role needs to have a trust relationship that allows the Comprehend service to assume it\n",
    "2. Ensure that the SageMaker role has a policy which provides iam:passrole permissions on the `DATA_ACCESS_ROLE_ARN` to allow the passing of the data access role to the SageMaker service\n",
    "3. Ensure that the STS service has been enabled for the `REGION` in the account. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import boto3\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-east-2'\n",
    "\n",
    "DATA_ACCESS_ROLE_ARN = 'arn:aws:iam::632354576168:role/HandsOnLabsComprehendDataAccessRole'\n",
    "DATA_BUCKET = 'awshandson-comprehend'\n",
    "IMDB_DATA_PREFIX = 'data/imdb/imdb-data-sample.csv'\n",
    "\n",
    "TOPICS_OUTPUT_PREFIX = 'imdb-topics'\n",
    "\n",
    "SAMPLE_SIZE = 1000\n",
    "MAX_TEXT_LENGTH = 4900\n",
    "BATCH_SIZE = 25\n",
    "PREDICTION_THRESHOLD = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of AWS Comprehend functionality and API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get a client to access the AWS Comprehend API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehend = boto3.client('comprehend', region_name=REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sample sentence to demonstrate key Comprehend functionalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sentence = \"Itâ€™s always a great day when I can randomly put my equestrian knowledge to good use at work! #AWS #BePeculiar\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Key phrase detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Score': 0.9999999403953552, 'Text': 'a great day', 'BeginOffset': 12, 'EndOffset': 23}\n",
      "{'Score': 1.0, 'Text': 'my equestrian knowledge', 'BeginOffset': 48, 'EndOffset': 71}\n",
      "{'Score': 0.9999207258224487, 'Text': 'good use', 'BeginOffset': 75, 'EndOffset': 83}\n",
      "{'Score': 0.9999996423721313, 'Text': 'work', 'BeginOffset': 87, 'EndOffset': 91}\n"
     ]
    }
   ],
   "source": [
    "phrases = comprehend.detect_key_phrases(Text=sample_sentence, LanguageCode='en')\n",
    "for phrase in phrases['KeyPhrases']:\n",
    "    print(phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sentence_ner = \"\"\"\n",
    "500 men just stood there and watched. All the great knights of the Seven Kingdoms. You think anyone said a word, lifted a finger?\n",
    "No, Lord Stark. 500 men and this room was silent as a crypt. Except for the screams, of course, and the Mad King laughing. \n",
    "And later... When I watched the Mad King die, I remembered him laughing as your father burned... It felt like justice.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Write the code to do Named Entity Recognition using AWS Comprehend and output the results. \n",
    "##### Hint: Follow the pattern of the key phrase detection section above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Score': 0.6978814601898193, 'Type': 'TITLE', 'Text': '#AWS', 'BeginOffset': 93, 'EndOffset': 97}\n"
     ]
    }
   ],
   "source": [
    "### Enter your code here ###\n",
    "entities = comprehend.detect_entities(Text=sample_sentence, LanguageCode='en')\n",
    "for entity in entities['Entities']:\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Which one of the three feedbacks below would get the highest Positive score?\n",
    "2. Which one of the sarcastic sentences would Comprehend be able to detect?\n",
    "3. Replace the words 'call out' with 'mention' in 'feedback_1'. How does the sentiment score change?\n",
    "\n",
    "Also, to all three questions, why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis_sentences = dict()\n",
    "sentiment_analysis_sentences['feedback_1'] = \"\"\"Hey John,\n",
    "\n",
    "I wanted to call out all the work you've been doing for the social front of the Melbourne office. \n",
    "\n",
    "It's been great having more people actively involved in setting up events on a regular basis to give consultants an opportunity to catch up and team build outside of work contexts. \n",
    "Between the Hiking group and the Computer Games initiative the office has been much more active socially thanks to you and your inputs. \n",
    "\n",
    "Keep up the good work and thanks for making Servian a more interesting place to work.\n",
    "\n",
    "Regards, \n",
    "Clare\"\"\"\n",
    "\n",
    "sentiment_analysis_sentences['feedback_2'] = \"\"\"\n",
    "Laura, great work on creating the model deployment pipeline. You delivered independently with minimal direction and worked through blockers independently.\n",
    "And with extensive documentation too - once again excellent work.\n",
    "\"\"\"\n",
    "\n",
    "sentiment_analysis_sentences['feedback_3'] = \"\"\"\n",
    "Phillip is fantastic at doing her job in a way that impacts others in a not positive way, I would like to mention that Phillip is excellent at \n",
    "arriving not on time and with a very ungood attitude\n",
    "\"\"\"\n",
    "\n",
    "sentiment_analysis_sentences['sarcasm_1'] = \"His ignorance was an Empire State Building of ignorance - you had to admire it for its size\"\n",
    "\n",
    "sentiment_analysis_sentences['sarcasm_2'] = \"You have the aroma and intelligence of a great ape\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Positive': 0.8853756189346313, 'Negative': 0.0004674461670219898, 'Neutral': 0.11415435373783112, 'Mixed': 2.640103730300325e-06}\n"
     ]
    }
   ],
   "source": [
    "sentiment = comprehend.detect_sentiment(Text=sentiment_analysis_sentences['feedback_1'], LanguageCode='en')\n",
    "print(sentiment['SentimentScore'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text analysis on the IMDB Dataset (Movie Reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read IMDB dataset from S3 into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3 = boto3.client('s3')\n",
    "obj = s3.get_object(Bucket=DATA_BUCKET, Key=IMDB_DATA_PREFIX)\n",
    "\n",
    "df = pd.read_csv(obj['Body'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Alternative method of reading dataset to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('s3://' + DATA_BUCKET + \"/\" + IMDB_DATA_PREFIX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Detecting sentiment of one review selected at random. \n",
    "\n",
    "##### Have a play by running the cell multiple times. Do the predicted sentiment scores align with your human-level understanding and the labels provided?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: 643\n",
      "\n",
      "Review Text: Angela (Sandra Bullock) is a computer expert but, being shy and somewhat of a recluse, she does all of her work from the confines of her condo. Just as she is about to take a vacation in Mexico, a co-worker sends her a computer disc with disturbing information on it. Angela agrees to meet with her fellow employee but he mysteriously dies in a plane crash. Angela heads to Mexico but takes the disc with her. While she is sunning on the beach, a terrific looking gentleman named Jack (Jeremy Northam) makes overtures to her. She falls for them and the two end up on a boat to Cozumel. However, Jack works for the folks who generated the secret information on the disc and he is out to get it. Even after Angela escapes from his clutches and lands back in the USA, Jack makes things difficult. He changes Angela's identity on every computer across the nation, making her lose her condo, her bank account, everything. Can Angela, a computer whiz, beat Jack at his own game? This very exciting movie has many assets. First, Bullock and Northam are two very beautiful, interesting actors and their presence adds immediate captivation. The script is very clever and sure in its knowledge of the capabilities of computers and their relevance in today's world. The costumes, sets, production, and direction of the movie are also quite wonderful. And, despite how it sounds, there is a great deal of exciting action as Angela goes on the run to defeat her enemy. If you love thrillers without unnecessary bloodshed or violence, this is a great choice. It delivers twists and turns with great frequency, making it possible for the viewer to \"net\" a very good evening of entertainment.\n",
      "\n",
      "Predicted sentiment: {'Positive': 0.5883938670158386, 'Negative': 0.07305614650249481, 'Neutral': 0.3383963406085968, 'Mixed': 0.0001536133058834821},\n",
      "\n",
      "Actual sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "import random as rand\n",
    "\n",
    "review_number = rand.randint(1,len(df))\n",
    "\n",
    "sample_review_object = df.iloc[review_number, ]\n",
    "sample_review_text = sample_review_object['review']\n",
    "\n",
    "sample_review_sentiment = comprehend.detect_sentiment(Text=sample_review_text, LanguageCode='en')\n",
    "\n",
    "print(f\"Review: {review_number}\\n\\n\\\n",
    "Review Text: {sample_review_text}\\n\\n\\\n",
    "Predicted sentiment: {sample_review_sentiment['SentimentScore']},\\n\\n\\\n",
    "Actual sentiment: {sample_review_object['sentiment']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Detecting sentiment of a batch of texts: Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "df['review_processed'] = df['review'].apply(lambda x: x[:MAX_TEXT_LENGTH])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Detecting sentiment of each batch. Loop through the batches and keep extending the `results` list with the output of `batch_detect_sentiment`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 0\n",
      "Processing batch 5\n",
      "Processing batch 10\n",
      "Processing batch 15\n",
      "Processing batch 20\n",
      "Processing batch 25\n",
      "Processing batch 30\n",
      "Processing batch 35\n"
     ]
    }
   ],
   "source": [
    "batch_size = BATCH_SIZE\n",
    "max_batch_index = SAMPLE_SIZE // batch_size\n",
    "results = []\n",
    "\n",
    "for batch_index in range(max_batch_index):\n",
    "    if batch_index % 5 == 0:\n",
    "        print(f\"Processing batch {batch_index}\")\n",
    "        \n",
    "    batch_text_list = df.iloc[batch_index*BATCH_SIZE:batch_index*BATCH_SIZE + batch_size,:]['review_processed'].tolist()\n",
    "    results.extend(comprehend.batch_detect_sentiment(TextList=batch_text_list, LanguageCode='en')['ResultList'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Printing out an element of the `results` list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Index': 0, 'Sentiment': 'POSITIVE', 'SentimentScore': {'Positive': 0.9654746055603027, 'Negative': 0.01993785984814167, 'Neutral': 0.014541912823915482, 'Mixed': 4.556140265776776e-05}}\n"
     ]
    }
   ],
   "source": [
    "print(results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating `sentiment_pred` column in DataFrame by using the 'Positive' scores reported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Enter your code here ###\n",
    "df['sentiment_pred'] = pd.Series([result['SentimentScore']['Positive'] for result in results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>sentiment_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.965475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.815299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.454442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.926993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label  sentiment_pred\n",
       "0  One of the other reviewers has mentioned that ...      1        0.965475\n",
       "1  A wonderful little production. <br /><br />The...      1        0.998547\n",
       "2  I thought this was a wonderful way to spend ti...      1        0.815299\n",
       "3  Basically there's a family where a little boy ...      0        0.454442\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...      1        0.991763\n",
       "5  Probably my all-time favorite movie, a story o...      1        0.997527\n",
       "6  I sure would like to see a resurrection of a u...      1        0.926993\n",
       "7  This show was an amazing, fresh & innovative i...      0        0.014710\n",
       "8  Encouraged by the positive comments about this...      0        0.014309\n",
       "9  If you like original gut wrenching laughter yo...      1        0.999517"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['review', 'label', 'sentiment_pred']].head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculating accuracy metrics: AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_values = df['label']\n",
    "predicted_values = df['sentiment_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.888231568990533\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(true_values, predicted_values, pos_label=1)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculating accuracy metrics: Precision and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8112033195020747,\n",
      "Recall: 0.780439121756487\n"
     ]
    }
   ],
   "source": [
    "### Enter your code here ###\n",
    "predicted_values_binary = df['sentiment_pred'].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "\n",
    "print(f\"Precision: {metrics.precision_score(true_values, predicted_values_binary)},\\n\\\n",
    "Recall: {metrics.recall_score(true_values, predicted_values_binary)}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start topics detection job setting\n",
    "input_s3_url = \"s3://\" + DATA_BUCKET + \"/\" + IMDB_DATA_PREFIX\n",
    "input_doc_format = \"ONE_DOC_PER_LINE\"\n",
    "output_s3_url = \"s3://\" + DATA_BUCKET + \"/\" + TOPICS_OUTPUT_PREFIX\n",
    "\n",
    "data_access_role_arn = DATA_ACCESS_ROLE_ARN\n",
    "number_of_topics = 4\n",
    "job_name = \"IMDB_Topic_Modelling_Job\"\n",
    "\n",
    "input_data_config = {\"S3Uri\": input_s3_url, \"InputFormat\": input_doc_format}\n",
    "output_data_config = {\"S3Uri\": output_s3_url}\n",
    "\n",
    "# Starts an asynchronous topic detection job.\n",
    "response = comprehend.start_topics_detection_job(NumberOfTopics=number_of_topics,\n",
    "                                                 InputDataConfig=input_data_config,\n",
    "                                                 OutputDataConfig=output_data_config,\n",
    "                                                 DataAccessRoleArn=data_access_role_arn,\n",
    "                                                 JobName=job_name)\n",
    "\n",
    "# Gets job_id\n",
    "job_id = response[\"JobId\"]\n",
    "print('job_id: ' + job_id)\n",
    "\n",
    "# It loops until JobStatus becomes 'COMPLETED' or 'FAILED'.\n",
    "while True:\n",
    "    result = comprehend.describe_topics_detection_job(JobId=job_id)\n",
    "    job_status = result[\"TopicsDetectionJobProperties\"][\"JobStatus\"]\n",
    "\n",
    "    if job_status in ['COMPLETED', 'FAILED']:\n",
    "        print(\"job_status: \" + job_status)\n",
    "        break\n",
    "    else:\n",
    "        print(\"job_status: \" + job_status)\n",
    "        time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use to debug if the job above fails\n",
    "# comprehend.describe_topics_detection_job(JobId=job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example topics generated (topic-terms.csv inside output.tar.gz which is written out to `DATA_BUCKET/TOPICS_OUTPUT_PREFIX` at the end of the job above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|topic|term|weight|\n",
    "| --- | --- | --- |\n",
    "|000|film|0.07013403|\n",
    "|000|positive|0.016125802|\n",
    "|000|work|0.0061104186|\n",
    "|000|performance|0.0053255544|\n",
    "|000|great|0.009274145|\n",
    "|000|feel|0.0068337116|\n",
    "|000|story|0.009006502|\n",
    "|000|director|0.0038702376|\n",
    "|000|character|0.006694102|\n",
    "|000|love|0.0063105687|\n",
    "|001|br|0.14845546|\n",
    "|001|show|0.003921953|\n",
    "|001|game|0.0022336794|\n",
    "|001|character|0.006027758|\n",
    "|001|woman|0.0021741905|\n",
    "|001|play|0.003455709|\n",
    "|001|shakespeare|0.0012397129|\n",
    "|001|write|0.002254727|\n",
    "|001|episode|0.001209998|\n",
    "|001|house|0.0016670021|\n",
    "|002|movie|0.10096688|\n",
    "|002|positive|0.02110654|\n",
    "|002|great|0.012690482|\n",
    "|002|story|0.0113774035|\n",
    "|002|love|0.008182541|\n",
    "|002|good|0.013601423|\n",
    "|002|message|0.004564077|\n",
    "|002|young|0.004554768|\n",
    "|002|fan|0.0047151013|\n",
    "|002|favorite|0.003373193|\n",
    "|003|movie|0.08092111|\n",
    "|003|bad|0.029862158|\n",
    "|003|negative|0.029115958|\n",
    "|003|wrong|0.014751226|\n",
    "|003|rate|0.009013734|\n",
    "|003|watch|0.01766251|\n",
    "|003|plot|0.010764287|\n",
    "|003|waste|0.0074185627|\n",
    "|003|stupid|0.0071981|\n",
    "|003|act|0.012075577|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
